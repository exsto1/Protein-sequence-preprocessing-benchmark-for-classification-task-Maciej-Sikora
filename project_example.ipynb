{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Benchmark comparison of protein sequence preprocessing effect on learning task for Pfam family classification\n",
    "\n",
    "Notebook below allows to play with parameters of the workflow and yield different results.\n",
    "As a default state it is set with parameters described in the paper as well as used as a base for plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 11:54:31.615926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-26 11:54:31.615959: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, interact_manual, fixed\n",
    "import sys\n",
    "from urllib import request\n",
    "from scripts.data_preparation_support import data_preparation, split_to_train_test\n",
    "from scripts.shorten_encoding import compress_protein_data_original, compress_protein_data_singletons, compress_protein_data_triplets, compress_protein_data_sum_of_triplets, compress_protein_data_sum_of_k_mers\n",
    "from scripts.prepare_vectors import split_data_to_classes, prepare_biovec_model, load_biovec_model_with_classes\n",
    "from scripts.prepare_input_stats import input_analysis\n",
    "from scripts.model_scripts.decision_trees import decision_tree_func\n",
    "from scripts.model_scripts.random_tree import random_tree_func\n",
    "from scripts.model_scripts.mlp import mlp_func\n",
    "from scripts.model_scripts.nearest_neighbours import nearest_neighbours_func\n",
    "from scripts.model_scripts.deep_learning import deep_learning_func\n",
    "from scripts.plotting_support import results_plot_benchmark, plot_sizes\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset\n",
    "In this project I provide already prepared - cleaned dataset used for the report, so download part below is commented out. However, if desired, parameters can be tweaked to obtain altered version.\n",
    "\n",
    "Raw data for this project is easily accessible by the Swissprot part of the Uniprot Database.\n",
    "Unfortunately, full file weights around 250Mb, so instead I provide link for download.\n",
    "\n",
    "In case server can't handle the download through Python, it is still possiblle to download tab-separated file directly\n",
    "from the website: [LINK](https://www.uniprot.org/uniprot/?query=reviewed%3Ayes&columns=id%2Cdatabase(Pfam)%2Corganism%2Csequence)\n",
    "\n",
    "It suggested, although not neccessary, to put downloaded file into ./data/full directory for clarity and ease of use of the default values below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# url=\"https://www.uniprot.org/uniprot/?query=reviewed:yes&format=tab&columns=id,database(Pfam),organism,sequence\"\n",
    "# request.urlretrieve(url, \"./data/full/uniprot-reviewed_yes.tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_prepare_widget():\n",
    "    org_w = widgets.BoundedIntText(value=2000, min=1, max=5000, step=1, description=\"Organisms\")\n",
    "    fam_w = widgets.BoundedIntText(value=10, min=1, max=200, step=1, description=\"Families\")\n",
    "    infile = widgets.Text(value=\"./data/full/uniprot-reviewed_yes.tab\",  description=\"Input path\")\n",
    "    outfile = widgets.Text(value=\"./data/data_file.fasta\", description=\"Output path\")\n",
    "\n",
    "    widget = interact_manual.options(manual_name=\"Prepare data\")\n",
    "    widget(data_preparation, n_org=org_w, n_fam=fam_w, file_path=infile, outfile_path=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23ba2e65b3a4b8c93eae1d9fcff5da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='./data/full/uniprot-reviewed_yes.tab', description='Input path'), Text(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_prepare_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At this point of code raw Swissprot data was filtered by the top number of organisms and picked proteins containing single domain from top biggest families.\n",
    "\n",
    "However, before splitting our data to train and test, we want to first adress very simmilar sequences.\n",
    "It can be done using CD-HIT package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_cdhit(input_f=\"./data/to_cluster/data_file.fasta\", output_f=\"./data/to_cluster/data_file_outttt.fasta\", c=\"0.99\"):\n",
    "    c = str(c)\n",
    "    print(\"Begin CD-HIT\")\n",
    "    os.system(f\"./CD-HIT/cd-hit -i {input_f} -o {output_f} -c {c}\")\n",
    "\n",
    "\n",
    "def run_cdhit_widget():\n",
    "    c = widgets.BoundedFloatText(value=0.99, min=0.7, max=1, description=\"Simmilarity\")\n",
    "    infile = widgets.Text(value=\"./data/data_file.fasta\",  description=\"Input path\")\n",
    "    outfile = widgets.Text(value=\"./data/clustering/data_file_clustered.fasta\", description=\"Output path\")\n",
    "\n",
    "    widget = interact_manual.options(manual_name=\"Prepare data\")\n",
    "    widget(run_cdhit, c=c, input_f=infile, output_f=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3284eb13be48659f2f0838ac6f68fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='./data/data_file.fasta', description='Input path'), Text(value='./data/clust…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_cdhit_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now our data is cleaned out and ready to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data processing\n",
    "\n",
    "For this project data is processed in multiple ways.\n",
    "\n",
    " - Standard single-letter encoding\n",
    " - Conversion into numbers and using int-8 encoding\n",
    " - Conversion into 3-mers, encoding each 3-mer as a number and using int-16 encoding\n",
    " - Conversion into 3-mers, calculating count of the most popular triplets in sequences.\n",
    " - Conversion into k-mers, grouping with allowed edit distance and counting existance of fragments in group. (7-mers with edit distance 3)\n",
    " - Using Biovec vector encoder\n",
    "\n",
    "First we need to split our data into training and test parts.\n",
    "To avoid dominance of the biggest families, training data will contain the same number of sequences for each PFAM family.\n",
    "\n",
    "### Warning!\n",
    "Please analyse the histogram first before providing number of sequences per family to train.\n",
    "Families with number of representatives lower than provided will be filtered out!\n",
    "\n",
    "Sometimes it might be beneficial to filter out couple families with low coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def histogram_widget():\n",
    "    infile = widgets.Text(value=\"./data/clustering/data_file_clustered.fasta\",  description=\"Input path\")\n",
    "    widget = interact_manual.options(manual_name=\"Prepare histogram\")\n",
    "\n",
    "    widget(input_analysis, input_file=infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88cc45f9a8d4ffa8733b32db6e297de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='./data/clustering/data_file_clustered.fasta', description='Input path'), But…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_to_train_test_widget():\n",
    "    train_val = widgets.BoundedIntText(value=790, min=1, max=5000, step=1, description=\"N. to train\")\n",
    "    infile = widgets.Text(value=\"./data/clustering/data_file_clustered.fasta\",  description=\"Input path\")\n",
    "    outfile = widgets.Text(value=\"./data/clean_dataset.pkl\", description=\"Output path\")\n",
    "\n",
    "    widget = interact_manual.options(manual_name=\"Prepare data\")\n",
    "    new_val = widget(split_to_train_test, train_val=train_val, infile=infile, outfile=outfile)\n",
    "    return new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c2132e10224ff9a48f149a5aa1d72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=650, description='N. to train', max=5000, min=1), Text(value='./dat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_val_global = split_to_train_test_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This process will save data into convenient pickle object. This way instead of keeping 4 separate files or trying to split our data in one file we can easily load a list prepared to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compress_protein_data_original(infile='./data/clean_dataset.pkl', outfile='./data/clean_dataset_original.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compress_protein_data_singletons(infile='./data/clean_dataset.pkl', outfile='./data/clean_dataset_singletons.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compress_protein_data_triplets(infile='./data/clean_dataset.pkl', outfile='./data/clean_dataset_triplets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compress_protein_data_sum_of_triplets(infile='./data/clean_dataset.pkl', outfile='./data/clean_dataset_sum_triplets.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Shorten sum k-mer\n",
    "\n",
    "Plugin below allows for customized summed k-mer encoding. Parameters:\n",
    "\n",
    "- input, output files\n",
    "- K-mer length - size of the moving, overalpping window\n",
    "- Min. occurences - How many times certain k-mer must exist in all sequences to be taken into consideration (filtering out highly mutated fragments, picking \"popularity\" strength)\n",
    "- Allowed edit distance - Fragments with edit distance equal or lower than provided to already found fragments will be united into one group. Example: with value 1 strings: AAAAA and AAAAB will be united while AAAAA and AAABB treated as separate groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def shorten_kmer_widget():\n",
    "    infile = widgets.Text(value=\"./data/clean_dataset.pkl\",  description=\"Input path\")\n",
    "    outfile = widgets.Text(value=\"./data/clean_dataset_sum_k_mers.pkl\", description=\"Output path\")\n",
    "    n_val = widgets.BoundedIntText(value=7, min=3, max=15, step=1, description=\"k-mer length\")\n",
    "    k_val = widgets.BoundedIntText(value=20, min=1, max=1000, step=1, description=\"min. occurences\")\n",
    "    edit_val = widgets.BoundedIntText(value=2, min=1, max=3, step=1, description=\"allowed edit distance\")\n",
    "\n",
    "    widget = interact_manual.options(manual_name=\"Prepare data\")\n",
    "    widget(compress_protein_data_sum_of_k_mers, n=n_val, k=k_val, edit=edit_val, infile=infile, outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shorten_kmer_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Biovec\n",
    "\n",
    "Biovec model is built on top of the original implementation, thus data handling must be a bit different, to fit authors requirements.\n",
    "Sequences must be split into class fasta files, and one combined with identical names.\n",
    "Combined file will be used to generate model, wchich will be then saved.\n",
    "This saved model, is next loaded again, but this time, we also provide family information.\n",
    "\n",
    "After this procedure we are finally left with a data ready to split into training and test, perform learning and predictions.\n",
    "\n",
    "\n",
    "### Warning !\n",
    "This time widget is not provided, because of the ./data/vectors/combined_corpus.fasta file.\n",
    "If Biovec recognizes this file it will skip creating a new model.\n",
    "That's why paths here are fixed to ensure, old corpus file is deleted.\n",
    "\n",
    "### Warning !\n",
    "It might happen, that during loading process there will be information, that model did not train on certain triplets.\n",
    "It is connected with fragments containing extended alphabet like \"X\" and are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "split_data_to_classes(infile=\"./data/clean_dataset.pkl\", output_folder=\"./data/vectors/class_folder\",\n",
    "                          output_combined_file=\"./data/vectors/combined.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prepare_biovec_model(infile=\"./data/vectors/combined.fasta\", outfile=\"./data/vectors/ProtVec_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_biovec_widget():\n",
    "    train_val = widgets.BoundedIntText(value=790, min=1, max=5000, step=1, description=\"N. to train\")\n",
    "\n",
    "    widget = interact_manual.options(manual_name=\"Prepare data\")\n",
    "\n",
    "    new_val = widget(load_biovec_model_with_classes, train_size=train_val, input_model=fixed(\"./data/vectors/ProtVec_model.model\"), class_folder=fixed(\"./data/vectors/class_folder\"), outfile=fixed('./data/clean_dataset_biovec.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17372eee1f05436eb14054a6a838360b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=650, description='N. to train', max=5000, min=1), Button(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_biovec_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Now, that we have all data prepared, we can evaluate them both in accuracy and runtime.\n",
    "\n",
    "Several models will be created - please note, that not all of them are equally suitable for this kind of data - the point is in efficiency comparison.\n",
    "\n",
    "- Decision trees\n",
    "- Random trees\n",
    "- Nearest Neighbours\n",
    "- MLP\n",
    "- Simple Machine Learning with Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_times = []\n",
    "all_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Best model:\n",
      "- max_depth: 20\n",
      "----- Model accuracy: 0.169\n",
      "----- Refit runtime: 1.7387\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Best model:\n",
      "- max_depth: 40\n",
      "----- Model accuracy: 0.701\n",
      "----- Refit runtime: 1.8949\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Best model:\n",
      "- max_depth: 10\n",
      "----- Model accuracy: 0.649\n",
      "----- Refit runtime: 0.9368\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Best model:\n",
      "- max_depth: 90\n",
      "----- Model accuracy: 0.829\n",
      "----- Refit runtime: 3.8933\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Best model:\n",
      "- max_depth: 100\n",
      "----- Model accuracy: 0.309\n",
      "----- Refit runtime: 10.2369\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Best model:\n",
      "- max_depth: 70\n",
      "----- Model accuracy: 0.713\n",
      "----- Refit runtime: 0.0496\n"
     ]
    }
   ],
   "source": [
    "s1 = time()\n",
    "acc1, refit1 = decision_tree_func(\"./data/clean_dataset_original.pkl\")\n",
    "t1 = time() - s1\n",
    "\n",
    "s2 = time()\n",
    "acc2, refit2 = decision_tree_func(\"./data/clean_dataset_singletons.pkl\")\n",
    "t2 = time() - s2\n",
    "\n",
    "s3 = time()\n",
    "acc3, refit3 = decision_tree_func(\"./data/clean_dataset_triplets.pkl\")\n",
    "t3 = time() - s3\n",
    "\n",
    "s4 = time()\n",
    "acc4, refit4 = decision_tree_func(\"./data/clean_dataset_sum_triplets.pkl\")\n",
    "t4 = time() - s4\n",
    "\n",
    "s5 = time()\n",
    "acc5, refit5 = decision_tree_func(\"./data/clean_dataset_sum_k_mers.pkl\")\n",
    "t5 = time() - s5\n",
    "\n",
    "s6 = time()\n",
    "acc6, refit6 = decision_tree_func(\"./data/clean_dataset_biovec.pkl\")\n",
    "t6 = time() - s6\n",
    "\n",
    "t1 = round(t1, 2)\n",
    "t2 = round(t2, 2)\n",
    "t3 = round(t3, 2)\n",
    "t4 = round(t4, 2)\n",
    "t5 = round(t5, 2)\n",
    "t6 = round(t6, 2)\n",
    "\n",
    "all_times.append([t1, t2, t3, t4, t5, t6])\n",
    "all_accs.append([acc1, acc2, acc3, acc4, acc5, acc6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic | Original | Singletons | Triplets | Sum Triplets | Sum K-mers | Biovec\n",
      "----------|----------|------------|----------|--------------|------------|--------\n",
      "Time      | 1.7387 \t | 1.8949 \t | 0.9368 \t | 3.8933 \t | 10.2369 \t | 0.0496 \t\n",
      "Accuracy  | 0.1686 \t | 0.701 \t | 0.6486 \t | 0.8286 \t | 0.3086 \t | 0.7126 \t\n"
     ]
    }
   ],
   "source": [
    "print(f\"Statistic | Original | Singletons | Triplets | Sum Triplets | Sum K-mers | Biovec\")\n",
    "print(f\"----------|----------|------------|----------|--------------|------------|--------\")\n",
    "print(f\"Time      | {t1} \\t | {t2} \\t | {t3} \\t | {t4} \\t | {t5} \\t | {t6} \\t\")\n",
    "print(f\"Accuracy  | {acc1} \\t | {acc2} \\t | {acc3} \\t | {acc4} \\t | {acc5} \\t | {acc6} \\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
      "Best model:\n",
      "- random_state: 1234\n",
      "- max_depth: 20\n",
      "- max_features: 20\n",
      "----- Model accuracy: 0.419\n",
      "----- Refit runtime: 2.6424\n",
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
      "Best model:\n",
      "- random_state: 1234\n",
      "- max_depth: 30\n",
      "- max_features: 20\n",
      "----- Model accuracy: 0.802\n",
      "----- Refit runtime: 2.5483\n",
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
      "[CV 1/2] END ......................max_depth=10;, score=0.632 total time=   1.2s\n",
      "[CV 1/2] END ......................max_depth=20;, score=0.647 total time=   1.0s\n",
      "[CV 1/2] END ......................max_depth=30;, score=0.649 total time=   1.0s\n",
      "[CV 1/2] END ......................max_depth=40;, score=0.643 total time=   0.9s\n",
      "[CV 1/2] END ......................max_depth=50;, score=0.640 total time=   1.1s\n",
      "[CV 1/2] END ......................max_depth=60;, score=0.635 total time=   1.2s\n",
      "[CV 1/2] END ......................max_depth=70;, score=0.637 total time=   1.1s\n",
      "[CV 1/2] END ......................max_depth=80;, score=0.639 total time=   1.2s\n",
      "[CV 1/2] END ......................max_depth=90;, score=0.645 total time=   1.0s\n",
      "[CV 1/2] END .....................max_depth=100;, score=0.637 total time=   1.0s\n",
      "[CV 1/2] END ......................max_depth=10;, score=0.640 total time=   0.9s\n",
      "[CV 2/2] END ......................max_depth=20;, score=0.641 total time=   0.9s\n",
      "[CV 1/2] END ......................max_depth=30;, score=0.657 total time=   1.0s\n",
      "[CV 2/2] END ......................max_depth=40;, score=0.644 total time=   0.9s\n",
      "[CV 1/2] END ......................max_depth=50;, score=0.656 total time=   1.0s\n",
      "[CV 2/2] END ......................max_depth=60;, score=0.638 total time=   0.9s\n",
      "[CV 1/2] END ......................max_depth=70;, score=0.650 total time=   1.0s\n",
      "[CV 2/2] END ......................max_depth=80;, score=0.644 total time=   0.9s\n",
      "[CV 1/2] END ......................max_depth=90;, score=0.657 total time=   1.0s\n",
      "[CV 2/2] END .....................max_depth=100;, score=0.639 total time=   0.9s\n",
      "[CV 2/2] END ......................max_depth=10;, score=0.620 total time=   0.5s\n",
      "[CV 1/2] END ......................max_depth=20;, score=0.596 total time=   0.6s\n",
      "[CV 2/2] END ......................max_depth=30;, score=0.613 total time=   0.6s\n",
      "[CV 2/2] END ......................max_depth=40;, score=0.612 total time=   0.6s\n",
      "[CV 1/2] END ......................max_depth=50;, score=0.605 total time=   0.8s\n",
      "[CV 1/2] END ......................max_depth=60;, score=0.603 total time=   0.6s\n",
      "[CV 2/2] END ......................max_depth=70;, score=0.619 total time=   0.5s\n",
      "[CV 2/2] END ......................max_depth=80;, score=0.610 total time=   0.5s\n",
      "[CV 1/2] END ......................max_depth=90;, score=0.597 total time=   0.6s\n",
      "[CV 1/2] END .....................max_depth=100;, score=0.602 total time=   0.6s\n",
      "[CV 2/2] END ......................max_depth=10;, score=0.718 total time=   2.0s\n",
      "[CV 1/2] END ......................max_depth=20;, score=0.780 total time=   2.1s\n",
      "[CV 2/2] END ......................max_depth=30;, score=0.790 total time=   2.2s\n",
      "[CV 1/2] END ......................max_depth=40;, score=0.801 total time=   2.3s\n",
      "[CV 2/2] END ......................max_depth=50;, score=0.793 total time=   2.1s\n",
      "[CV 1/2] END ......................max_depth=60;, score=0.792 total time=   2.2s\n",
      "[CV 2/2] END ......................max_depth=70;, score=0.784 total time=   2.0s\n",
      "[CV 1/2] END ......................max_depth=80;, score=0.787 total time=   2.2s\n",
      "[CV 1/2] END ......................max_depth=90;, score=0.796 total time=   2.2s\n",
      "[CV 2/2] END .....................max_depth=100;, score=0.784 total time=   2.0s\n",
      "[CV 1/2] END ......................max_depth=10;, score=0.199 total time=   1.6s\n",
      "[CV 2/2] END ......................max_depth=20;, score=0.226 total time=   2.5s\n",
      "[CV 2/2] END ......................max_depth=30;, score=0.237 total time=   3.3s\n",
      "[CV 2/2] END ......................max_depth=40;, score=0.249 total time=   3.8s\n",
      "[CV 2/2] END ......................max_depth=50;, score=0.259 total time=   4.4s\n",
      "[CV 2/2] END ......................max_depth=60;, score=0.267 total time=   4.8s\n",
      "[CV 2/2] END ......................max_depth=70;, score=0.274 total time=   5.1s\n",
      "[CV 2/2] END ......................max_depth=80;, score=0.282 total time=   5.4s\n",
      "[CV 2/2] END ......................max_depth=90;, score=0.293 total time=   5.5s\n",
      "[CV 2/2] END .....................max_depth=100;, score=0.296 total time=   5.3s\n",
      "[CV 2/2] END ......................max_depth=10;, score=0.620 total time=   0.0s\n",
      "[CV 1/2] END ......................max_depth=20;, score=0.663 total time=   0.0s\n",
      "[CV 1/2] END ......................max_depth=40;, score=0.658 total time=   0.0s\n",
      "[CV 2/2] END ......................max_depth=40;, score=0.618 total time=   0.0s\n",
      "[CV 1/2] END ......................max_depth=60;, score=0.678 total time=   0.0s\n",
      "[CV 2/2] END ......................max_depth=60;, score=0.643 total time=   0.0s\n",
      "[CV 1/2] END ......................max_depth=90;, score=0.676 total time=   0.0s\n",
      "[CV 2/2] END ......................max_depth=90;, score=0.623 total time=   0.0s\n",
      "[CV 1/2] END .....................max_depth=100;, score=0.666 total time=   0.0s\n",
      "[CV 2/2] END .....................max_depth=100;, score=0.641 total time=   0.0s\n",
      "[CV 2/2] END max_depth=10, max_features=10, random_state=1234;, score=0.712 total time=   0.9s\n",
      "[CV 2/2] END max_depth=10, max_features=15, random_state=1234;, score=0.727 total time=   1.0s\n",
      "[CV 1/2] END max_depth=10, max_features=20, random_state=1234;, score=0.721 total time=   1.2s\n",
      "[CV 1/2] END max_depth=20, max_features=10, random_state=1234;, score=0.749 total time=   1.2s\n",
      "[CV 1/2] END max_depth=20, max_features=15, random_state=1234;, score=0.754 total time=   1.4s\n",
      "[CV 1/2] END max_depth=20, max_features=20, random_state=1234;, score=0.758 total time=   1.7s\n",
      "[CV 1/2] END max_depth=30, max_features=10, random_state=1234;, score=0.756 total time=   1.2s\n",
      "[CV 1/2] END max_depth=30, max_features=15, random_state=1234;, score=0.752 total time=   1.4s\n",
      "[CV 1/2] END max_depth=30, max_features=20, random_state=1234;, score=0.758 total time=   1.7s\n",
      "[CV 1/2] END max_depth=40, max_features=10, random_state=1234;, score=0.756 total time=   1.2s\n",
      "[CV 1/2] END max_depth=40, max_features=15, random_state=1234;, score=0.752 total time=   1.4s\n",
      "[CV 1/2] END max_depth=40, max_features=20, random_state=1234;, score=0.758 total time=   1.7s\n",
      "[CV 1/2] END max_depth=50, max_features=10, random_state=1234;, score=0.756 total time=   1.2s\n",
      "[CV 1/2] END max_depth=50, max_features=15, random_state=1234;, score=0.752 total time=   1.4s\n",
      "[CV 1/2] END max_depth=50, max_features=20, random_state=1234;, score=0.758 total time=   1.7s\n",
      "[CV 1/2] END max_depth=10, max_features=10, random_state=1234;, score=0.715 total time=   0.9s\n",
      "[CV 2/2] END max_depth=10, max_features=15, random_state=1234;, score=0.731 total time=   1.1s\n",
      "[CV 1/2] END max_depth=10, max_features=20, random_state=1234;, score=0.727 total time=   1.3s\n",
      "[CV 1/2] END max_depth=20, max_features=10, random_state=1234;, score=0.753 total time=   1.2s\n",
      "[CV 1/2] END max_depth=20, max_features=15, random_state=1234;, score=0.754 total time=   1.4s\n",
      "[CV 1/2] END max_depth=20, max_features=20, random_state=1234;, score=0.763 total time=   1.6s\n",
      "[CV 2/2] END max_depth=30, max_features=10, random_state=1234;, score=0.761 total time=   1.2s\n",
      "[CV 2/2] END max_depth=30, max_features=15, random_state=1234;, score=0.761 total time=   1.4s\n",
      "[CV 2/2] END max_depth=30, max_features=20, random_state=1234;, score=0.768 total time=   1.6s\n",
      "[CV 1/2] END max_depth=40, max_features=10, random_state=1234;, score=0.757 total time=   1.2s\n",
      "[CV 1/2] END max_depth=40, max_features=15, random_state=1234;, score=0.761 total time=   1.4s\n",
      "[CV 1/2] END max_depth=40, max_features=20, random_state=1234;, score=0.766 total time=   1.6s\n",
      "[CV 1/2] END max_depth=50, max_features=10, random_state=1234;, score=0.757 total time=   1.2s\n",
      "[CV 1/2] END max_depth=50, max_features=15, random_state=1234;, score=0.761 total time=   1.4s\n",
      "[CV 1/2] END max_depth=50, max_features=20, random_state=1234;, score=0.766 total time=   1.6s\n",
      "[CV 1/2] END max_depth=10, max_features=10, random_state=1234;, score=0.682 total time=   1.0s\n",
      "[CV 2/2] END max_depth=10, max_features=15, random_state=1234;, score=0.708 total time=   1.2s\n",
      "[CV 1/2] END max_depth=10, max_features=20, random_state=1234;, score=0.700 total time=   1.5s\n",
      "[CV 1/2] END max_depth=20, max_features=10, random_state=1234;, score=0.721 total time=   1.2s\n",
      "[CV 2/2] END max_depth=20, max_features=15, random_state=1234;, score=0.734 total time=   1.5s\n",
      "[CV 2/2] END ......................max_depth=10;, score=0.615 total time=   1.3s\n",
      "[CV 2/2] END ......................max_depth=20;, score=0.633 total time=   1.0s\n",
      "[CV 2/2] END ......................max_depth=30;, score=0.621 total time=   1.0s\n",
      "[CV 2/2] END ......................max_depth=40;, score=0.626 total time=   1.0s\n",
      "[CV 2/2] END ......................max_depth=50;, score=0.627 total time=   1.2s\n",
      "[CV 2/2] END ......................max_depth=60;, score=0.627 total time=   1.2s\n",
      "[CV 2/2] END ......................max_depth=70;, score=0.627 total time=   1.1s\n",
      "[CV 2/2] END ......................max_depth=80;, score=0.625 total time=   1.2s\n",
      "[CV 2/2] END ......................max_depth=90;, score=0.628 total time=   1.0s\n",
      "[CV 2/2] END .....................max_depth=100;, score=0.621 total time=   1.0s\n",
      "[CV 2/2] END ......................max_depth=10;, score=0.647 total time=   0.8s\n",
      "[CV 1/2] END ......................max_depth=20;, score=0.655 total time=   1.0s\n",
      "[CV 2/2] END ......................max_depth=30;, score=0.644 total time=   0.9s\n",
      "[CV 1/2] END ......................max_depth=40;, score=0.659 total time=   1.0s\n",
      "[CV 2/2] END ......................max_depth=50;, score=0.646 total time=   0.9s\n",
      "[CV 1/2] END ......................max_depth=60;, score=0.650 total time=   1.0s\n",
      "[CV 2/2] END ......................max_depth=70;, score=0.638 total time=   0.9s\n",
      "[CV 1/2] END ......................max_depth=80;, score=0.657 total time=   1.0s\n",
      "[CV 2/2] END ......................max_depth=90;, score=0.635 total time=   0.9s\n",
      "[CV 1/2] END .....................max_depth=100;, score=0.650 total time=   0.9s\n",
      "[CV 1/2] END ......................max_depth=10;, score=0.609 total time=   0.5s\n",
      "[CV 2/2] END ......................max_depth=20;, score=0.610 total time=   0.6s\n",
      "[CV 1/2] END ......................max_depth=30;, score=0.601 total time=   0.6s\n",
      "[CV 1/2] END ......................max_depth=40;, score=0.606 total time=   0.6s\n",
      "[CV 2/2] END ......................max_depth=50;, score=0.614 total time=   0.8s\n",
      "[CV 2/2] END ......................max_depth=60;, score=0.604 total time=   0.5s\n",
      "[CV 1/2] END ......................max_depth=70;, score=0.597 total time=   0.6s\n",
      "[CV 1/2] END ......................max_depth=80;, score=0.608 total time=   0.6s\n",
      "[CV 2/2] END ......................max_depth=90;, score=0.617 total time=   0.6s\n",
      "[CV 2/2] END .....................max_depth=100;, score=0.606 total time=   0.5s\n",
      "[CV 1/2] END ......................max_depth=10;, score=0.720 total time=   2.0s\n",
      "[CV 2/2] END ......................max_depth=20;, score=0.782 total time=   2.1s\n",
      "[CV 1/2] END ......................max_depth=30;, score=0.797 total time=   2.3s\n",
      "[CV 2/2] END ......................max_depth=40;, score=0.783 total time=   2.2s\n",
      "[CV 1/2] END ......................max_depth=50;, score=0.797 total time=   2.2s\n",
      "[CV 2/2] END ......................max_depth=60;, score=0.788 total time=   2.1s\n",
      "[CV 1/2] END ......................max_depth=70;, score=0.792 total time=   2.2s\n",
      "[CV 2/2] END ......................max_depth=80;, score=0.791 total time=   2.1s\n",
      "[CV 2/2] END ......................max_depth=90;, score=0.795 total time=   2.1s\n",
      "[CV 1/2] END .....................max_depth=100;, score=0.796 total time=   2.2s\n",
      "[CV 2/2] END ......................max_depth=10;, score=0.204 total time=   1.5s\n",
      "[CV 1/2] END ......................max_depth=20;, score=0.226 total time=   2.4s\n",
      "[CV 1/2] END ......................max_depth=30;, score=0.241 total time=   3.1s\n",
      "[CV 1/2] END ......................max_depth=40;, score=0.252 total time=   3.6s\n",
      "[CV 1/2] END ......................max_depth=50;, score=0.261 total time=   4.2s\n",
      "[CV 1/2] END ......................max_depth=60;, score=0.267 total time=   4.6s\n",
      "[CV 1/2] END ......................max_depth=70;, score=0.277 total time=   4.8s\n",
      "[CV 1/2] END ......................max_depth=80;, score=0.287 total time=   5.1s\n",
      "[CV 1/2] END ......................max_depth=90;, score=0.298 total time=   5.4s\n",
      "[CV 1/2] END .....................max_depth=100;, score=0.310 total time=   5.5s\n",
      "[CV 1/2] END ......................max_depth=10;, score=0.678 total time=   0.0s\n",
      "[CV 2/2] END ......................max_depth=20;, score=0.643 total time=   0.0s\n",
      "[CV 1/2] END ......................max_depth=30;, score=0.668 total time=   0.0s\n",
      "[CV 2/2] END ......................max_depth=30;, score=0.620 total time=   0.0s\n",
      "[CV 1/2] END ......................max_depth=50;, score=0.686 total time=   0.0s\n",
      "[CV 2/2] END ......................max_depth=50;, score=0.635 total time=   0.0s\n",
      "[CV 1/2] END ......................max_depth=70;, score=0.686 total time=   0.0s\n",
      "[CV 2/2] END ......................max_depth=70;, score=0.663 total time=   0.0s\n",
      "[CV 1/2] END ......................max_depth=80;, score=0.658 total time=   0.0s\n",
      "[CV 2/2] END ......................max_depth=80;, score=0.630 total time=   0.0s\n",
      "[CV 1/2] END max_depth=10, max_features=10, random_state=1234;, score=0.705 total time=   0.9s\n",
      "[CV 1/2] END max_depth=10, max_features=15, random_state=1234;, score=0.720 total time=   1.0s\n",
      "[CV 2/2] END max_depth=10, max_features=20, random_state=1234;, score=0.720 total time=   1.2s\n",
      "[CV 2/2] END max_depth=20, max_features=10, random_state=1234;, score=0.754 total time=   1.2s\n",
      "[CV 2/2] END max_depth=20, max_features=15, random_state=1234;, score=0.753 total time=   1.4s\n",
      "[CV 2/2] END max_depth=20, max_features=20, random_state=1234;, score=0.765 total time=   1.7s\n",
      "[CV 2/2] END max_depth=30, max_features=10, random_state=1234;, score=0.751 total time=   1.2s\n",
      "[CV 2/2] END max_depth=30, max_features=15, random_state=1234;, score=0.749 total time=   1.5s\n",
      "[CV 2/2] END max_depth=30, max_features=20, random_state=1234;, score=0.761 total time=   1.7s\n",
      "[CV 2/2] END max_depth=40, max_features=10, random_state=1234;, score=0.751 total time=   1.2s\n",
      "[CV 2/2] END max_depth=40, max_features=15, random_state=1234;, score=0.749 total time=   1.4s\n",
      "[CV 2/2] END max_depth=40, max_features=20, random_state=1234;, score=0.761 total time=   1.7s\n",
      "[CV 2/2] END max_depth=50, max_features=10, random_state=1234;, score=0.751 total time=   1.2s\n",
      "[CV 2/2] END max_depth=50, max_features=15, random_state=1234;, score=0.749 total time=   1.5s\n",
      "[CV 2/2] END max_depth=50, max_features=20, random_state=1234;, score=0.761 total time=   1.7s\n",
      "[CV 2/2] END max_depth=10, max_features=10, random_state=1234;, score=0.727 total time=   0.9s\n",
      "[CV 1/2] END max_depth=10, max_features=15, random_state=1234;, score=0.720 total time=   1.1s\n",
      "[CV 2/2] END max_depth=10, max_features=20, random_state=1234;, score=0.732 total time=   1.3s\n",
      "[CV 2/2] END max_depth=20, max_features=10, random_state=1234;, score=0.759 total time=   1.2s\n",
      "[CV 2/2] END max_depth=20, max_features=15, random_state=1234;, score=0.765 total time=   1.4s\n",
      "[CV 2/2] END max_depth=20, max_features=20, random_state=1234;, score=0.761 total time=   1.6s\n",
      "[CV 1/2] END max_depth=30, max_features=10, random_state=1234;, score=0.757 total time=   1.2s\n",
      "[CV 1/2] END max_depth=30, max_features=15, random_state=1234;, score=0.761 total time=   1.4s\n",
      "[CV 1/2] END max_depth=30, max_features=20, random_state=1234;, score=0.766 total time=   1.6s\n",
      "[CV 2/2] END max_depth=40, max_features=10, random_state=1234;, score=0.759 total time=   1.2s\n",
      "[CV 2/2] END max_depth=40, max_features=15, random_state=1234;, score=0.761 total time=   1.4s\n",
      "[CV 2/2] END max_depth=40, max_features=20, random_state=1234;, score=0.767 total time=   1.6s\n",
      "[CV 2/2] END max_depth=50, max_features=10, random_state=1234;, score=0.759 total time=   1.2s\n",
      "[CV 2/2] END max_depth=50, max_features=15, random_state=1234;, score=0.761 total time=   1.4s\n",
      "[CV 2/2] END max_depth=50, max_features=20, random_state=1234;, score=0.767 total time=   1.6s\n",
      "[CV 2/2] END max_depth=10, max_features=10, random_state=1234;, score=0.696 total time=   1.0s\n",
      "[CV 1/2] END max_depth=10, max_features=15, random_state=1234;, score=0.687 total time=   1.2s\n",
      "[CV 2/2] END max_depth=10, max_features=20, random_state=1234;, score=0.716 total time=   1.5s\n",
      "[CV 2/2] END max_depth=20, max_features=10, random_state=1234;, score=0.735 total time=   1.2s\n",
      "[CV 1/2] END max_depth=20, max_features=15, random_state=1234;, score=0.720 total time=   1.5s\n",
      "Best model:\n",
      "- random_state: 1234\n",
      "- max_depth: 30\n",
      "- max_features: 20\n",
      "----- Model accuracy: 0.788\n",
      "----- Refit runtime: 3.4068\n",
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
      "Best model:\n",
      "- random_state: 1234\n",
      "- max_depth: 50\n",
      "- max_features: 20\n",
      "----- Model accuracy: 0.978\n",
      "----- Refit runtime: 2.9265\n",
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
      "Best model:\n",
      "- random_state: 1234\n",
      "- max_depth: 50\n",
      "- max_features: 15\n",
      "----- Model accuracy: 0.342\n",
      "----- Refit runtime: 4.0896\n",
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exsto/anaconda3/envs/benchmark_project_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:926: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:\n",
      "- random_state: 1234\n",
      "- max_depth: 10\n",
      "- max_features: 15\n",
      "----- Model accuracy: 0.884\n",
      "----- Refit runtime: 0.5977\n"
     ]
    }
   ],
   "source": [
    "s1 = time()\n",
    "acc1, refit1 = random_tree_func(\"./data/clean_dataset_original.pkl\")\n",
    "t1 = time() - s1\n",
    "\n",
    "s2 = time()\n",
    "acc2, refit2 = random_tree_func(\"./data/clean_dataset_singletons.pkl\")\n",
    "t2 = time() - s2\n",
    "\n",
    "s3 = time()\n",
    "acc3, refit3 = random_tree_func(\"./data/clean_dataset_triplets.pkl\")\n",
    "t3 = time() - s3\n",
    "\n",
    "s4 = time()\n",
    "acc4, refit4 = random_tree_func(\"./data/clean_dataset_sum_triplets.pkl\")\n",
    "t4 = time() - s4\n",
    "\n",
    "s5 = time()\n",
    "acc5, refit5 = random_tree_func(\"./data/clean_dataset_sum_k_mers.pkl\")\n",
    "t5 = time() - s5\n",
    "\n",
    "s6 = time()\n",
    "acc6, refit6 = random_tree_func(\"./data/clean_dataset_biovec.pkl\")\n",
    "t6 = time() - s6\n",
    "\n",
    "t1 = round(t1, 2)\n",
    "t2 = round(t2, 2)\n",
    "t3 = round(t3, 2)\n",
    "t4 = round(t4, 2)\n",
    "t5 = round(t5, 2)\n",
    "t6 = round(t6, 2)\n",
    "\n",
    "all_times.append([t1, t2, t3, t4, t5, t6])\n",
    "all_accs.append([acc1, acc2, acc3, acc4, acc5, acc6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic | Original | Singletons | Triplets | Sum Triplets | Sum K-mers | Biovec\n",
      "----------|----------|------------|----------|--------------|------------|--------\n",
      "Time      | 2.6424 \t | 2.5483 \t | 3.4068 \t | 2.9265 \t | 4.0896 \t | 0.5977 \t\n",
      "Accuracy  | 0.419 \t | 0.8019 \t | 0.7876 \t | 0.9781 \t | 0.3419 \t | 0.8839 \t\n"
     ]
    }
   ],
   "source": [
    "print(f\"Statistic | Original | Singletons | Triplets | Sum Triplets | Sum K-mers | Biovec\")\n",
    "print(f\"----------|----------|------------|----------|--------------|------------|--------\")\n",
    "print(f\"Time      | {t1} \\t | {t2} \\t | {t3} \\t | {t4} \\t | {t5} \\t | {t6} \\t\")\n",
    "print(f\"Accuracy  | {acc1} \\t | {acc2} \\t | {acc3} \\t | {acc4} \\t | {acc5} \\t | {acc6} \\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:\n",
      "- weights: distance\n",
      "- algorithm: auto\n",
      "----- Model accuracy: 0.331\n",
      "Best model:\n",
      "- weights: distance\n",
      "- algorithm: auto\n",
      "----- Model accuracy: 0.746\n",
      "Best model:\n",
      "- weights: distance\n",
      "- algorithm: auto\n",
      "----- Model accuracy: 0.73\n",
      "Best model:\n",
      "- weights: distance\n",
      "- algorithm: auto\n",
      "----- Model accuracy: 0.719\n",
      "Best model:\n",
      "- weights: distance\n",
      "- algorithm: auto\n",
      "----- Model accuracy: 0.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exsto/anaconda3/envs/benchmark_project_env/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:\n",
      "- weights: uniform\n",
      "- algorithm: auto\n",
      "----- Model accuracy: 0.871\n"
     ]
    }
   ],
   "source": [
    "s1 = time()\n",
    "acc1, refit1 = nearest_neighbours_func(\"./data/clean_dataset_original.pkl\")\n",
    "t1 = time() - s1\n",
    "\n",
    "s2 = time()\n",
    "acc2, refit2 = nearest_neighbours_func(\"./data/clean_dataset_singletons.pkl\")\n",
    "t2 = time() - s2\n",
    "\n",
    "s3 = time()\n",
    "acc3, refit3 = nearest_neighbours_func(\"./data/clean_dataset_triplets.pkl\")\n",
    "t3 = time() - s3\n",
    "\n",
    "s4 = time()\n",
    "acc4, refit4 = nearest_neighbours_func(\"./data/clean_dataset_sum_triplets.pkl\")\n",
    "t4 = time() - s4\n",
    "\n",
    "s5 = time()\n",
    "acc5, refit5 = nearest_neighbours_func(\"./data/clean_dataset_sum_k_mers.pkl\")\n",
    "t5 = time() - s5\n",
    "\n",
    "s6 = time()\n",
    "acc6, refit6 = nearest_neighbours_func(\"./data/clean_dataset_biovec.pkl\")\n",
    "t6 = time() - s6\n",
    "\n",
    "t1 = round(t1, 2)\n",
    "t2 = round(t2, 2)\n",
    "t3 = round(t3, 2)\n",
    "t4 = round(t4, 2)\n",
    "t5 = round(t5, 2)\n",
    "t6 = round(t6, 2)\n",
    "\n",
    "all_times.append([t1, t2, t3, t4, t5, t6])\n",
    "all_accs.append([acc1, acc2, acc3, acc4, acc5, acc6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic | Original | Singletons | Triplets | Sum Triplets | Sum K-mers | Biovec\n",
      "----------|----------|------------|----------|--------------|------------|--------\n",
      "Time      | 9.32 \t | 5.77 \t | 2.82 \t | 8.45 \t | 10.12 \t | 0.77 \t\n",
      "Accuracy  | 0.3314 \t | 0.7457 \t | 0.7305 \t | 0.719 \t | 0.301 \t | 0.8712 \t\n"
     ]
    }
   ],
   "source": [
    "print(f\"Statistic | Original | Singletons | Triplets | Sum Triplets | Sum K-mers | Biovec\")\n",
    "print(f\"----------|----------|------------|----------|--------------|------------|--------\")\n",
    "print(f\"Time      | {t1} \\t | {t2} \\t | {t3} \\t | {t4} \\t | {t5} \\t | {t6} \\t\")\n",
    "print(f\"Accuracy  | {acc1} \\t | {acc2} \\t | {acc3} \\t | {acc4} \\t | {acc5} \\t | {acc6} \\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exsto/anaconda3/envs/benchmark_project_env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:\n",
      "- hidden_layer_sizes: 128\n",
      "- activation: relu\n",
      "- solver: adam\n",
      "----- Model accuracy: 0.253\n",
      "----- Refit runtime: 86.0004\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "Best model:\n",
      "- hidden_layer_sizes: 128\n",
      "- activation: relu\n",
      "- solver: adam\n",
      "----- Model accuracy: 0.779\n",
      "----- Refit runtime: 49.0562\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "Best model:\n",
      "- hidden_layer_sizes: 128\n",
      "- activation: relu\n",
      "- solver: adam\n",
      "----- Model accuracy: 0.385\n",
      "----- Refit runtime: 18.7105\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "Best model:\n",
      "- hidden_layer_sizes: 128\n",
      "- activation: relu\n",
      "- solver: adam\n",
      "----- Model accuracy: 0.993\n",
      "----- Refit runtime: 18.5641\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    }
   ],
   "source": [
    "s1 = time()\n",
    "acc1, refit1 = mlp_func(\"./data/clean_dataset_original.pkl\")\n",
    "t1 = time() - s1\n",
    "\n",
    "s2 = time()\n",
    "acc2, refit2 = mlp_func(\"./data/clean_dataset_singletons.pkl\")\n",
    "t2 = time() - s2\n",
    "\n",
    "s3 = time()\n",
    "acc3, refit3 = mlp_func(\"./data/clean_dataset_triplets.pkl\")\n",
    "t3 = time() - s3\n",
    "\n",
    "s4 = time()\n",
    "acc4, refit4 = mlp_func(\"./data/clean_dataset_sum_triplets.pkl\")\n",
    "t4 = time() - s4\n",
    "\n",
    "s5 = time()\n",
    "acc5, refit5 = mlp_func(\"./data/clean_dataset_sum_k_mers.pkl\")\n",
    "t5 = time() - s5\n",
    "\n",
    "s6 = time()\n",
    "acc6, refit6 = mlp_func(\"./data/clean_dataset_biovec.pkl\")\n",
    "t6 = time() - s6\n",
    "\n",
    "t1 = round(t1, 2)\n",
    "t2 = round(t2, 2)\n",
    "t3 = round(t3, 2)\n",
    "t4 = round(t4, 2)\n",
    "t5 = round(t5, 2)\n",
    "t6 = round(t6, 2)\n",
    "\n",
    "all_times.append([t1, t2, t3, t4, t5, t6])\n",
    "all_accs.append([acc1, acc2, acc3, acc4, acc5, acc6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Statistic | Original | Singletons | Triplets | Sum Triplets | Sum K-mers | Biovec\")\n",
    "print(f\"----------|----------|------------|----------|--------------|------------|--------\")\n",
    "print(f\"Time      | {t1} \\t | {t2} \\t | {t3} \\t | {t4} \\t | {t5} \\t | {t6} \\t\")\n",
    "print(f\"Accuracy  | {acc1} \\t | {acc2} \\t | {acc3} \\t | {acc4} \\t | {acc5} \\t | {acc6} \\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "s1 = time()\n",
    "acc1, refit1 = deep_learning_func(\"./data/clean_dataset_original.pkl\")\n",
    "t1 = time() - s1\n",
    "\n",
    "s2 = time()\n",
    "acc2, refit2 = deep_learning_func(\"./data/clean_dataset_singletons.pkl\")\n",
    "t2 = time() - s2\n",
    "\n",
    "s3 = time()\n",
    "acc3, refit3 = deep_learning_func(\"./data/clean_dataset_triplets.pkl\")\n",
    "t3 = time() - s3\n",
    "\n",
    "s4 = time()\n",
    "acc4, refit4 = deep_learning_func(\"./data/clean_dataset_sum_triplets.pkl\")\n",
    "t4 = time() - s4\n",
    "\n",
    "s5 = time()\n",
    "acc5, refit5 = deep_learning_func(\"./data/clean_dataset_sum_k_mers.pkl\")\n",
    "t5 = time() - s5\n",
    "\n",
    "s6 = time()\n",
    "acc6, refit6 = deep_learning_func(\"./data/clean_dataset_biovec.pkl\")\n",
    "t6 = time() - s6\n",
    "\n",
    "t1 = round(t1, 2)\n",
    "t2 = round(t2, 2)\n",
    "t3 = round(t3, 2)\n",
    "t4 = round(t4, 2)\n",
    "t5 = round(t5, 2)\n",
    "t6 = round(t6, 2)\n",
    "\n",
    "all_times.append([t1, t2, t3, t4, t5, t6])\n",
    "all_accs.append([acc1, acc2, acc3, acc4, acc5, acc6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Statistic | Original | Singletons | Triplets | Sum Triplets | Sum K-mers | Biovec\")\n",
    "print(f\"----------|----------|------------|----------|--------------|------------|--------\")\n",
    "print(f\"Time      | {t1} \\t | {t2} \\t | {t3} \\t | {t4} \\t | {t5} \\t | {t6} \\t\")\n",
    "print(f\"Accuracy  | {acc1} \\t | {acc2} \\t | {acc3} \\t | {acc4} \\t | {acc5} \\t | {acc6} \\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "names = [\"Original\", \"Singletons\", \"Triplets\", \"Sum Triplets\", \"Sum K-mers\", \"Biovec\"]\n",
    "tests = [\"Decision trees\", \"Random trees\", \"Nearest neighbours\", \"MLP\", \"Machine Learning\"]\n",
    "print(all_times)\n",
    "print(all_accs)\n",
    "results_plot_benchmark(names, tests, all_times, all_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "files = [\"./data/clean_dataset_original.pkl\",\n",
    "         \"./data/clean_dataset_singletons.pkl\",\n",
    "         \"./data/clean_dataset_triplets.pkl\",\n",
    "         \"./data/clean_dataset_sum_triplets.pkl\",\n",
    "         \"./data/clean_dataset_sum_k_mers.pkl\",\n",
    "         \"./data/clean_dataset_biovec.pkl\"]\n",
    "\n",
    "plot_sizes(files, names, \"./presentation/images/sizes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}